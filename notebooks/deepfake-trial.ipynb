{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "39528153-a452-4927-834a-6aa957aff8b6",
    "_uuid": "455d32d0-7471-4f52-b245-8e398190ce0c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.325110Z",
     "iopub.status.busy": "2025-09-20T08:43:17.324764Z",
     "iopub.status.idle": "2025-09-20T08:43:17.330931Z",
     "shell.execute_reply": "2025-09-20T08:43:17.330344Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.325084Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import copy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "21ea40f1-3062-4f72-bc6b-a22fc217155a",
    "_uuid": "1108f210-12d5-4cf7-87ac-f31a1b3a2bf5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.332691Z",
     "iopub.status.busy": "2025-09-20T08:43:17.332445Z",
     "iopub.status.idle": "2025-09-20T08:43:17.357638Z",
     "shell.execute_reply": "2025-09-20T08:43:17.356943Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.332672Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "frames_per_video = 32\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "580fa5a9-0e5b-493b-a618-cb89a8d756fa",
    "_uuid": "3d307bcf-16dd-4ed2-be8d-053717311519",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "d84b301f-8d2f-401c-a36b-ba18cbb67d4d",
    "_uuid": "ed91e78c-1e7f-4f66-8507-3921dca7c3e9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.358599Z",
     "iopub.status.busy": "2025-09-20T08:43:17.358374Z",
     "iopub.status.idle": "2025-09-20T08:43:17.377791Z",
     "shell.execute_reply": "2025-09-20T08:43:17.377238Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.358580Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, video_paths, labels, transform=None, frames_per_video=frames_per_video):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.frames_per_video=frames_per_video\n",
    "\n",
    "      \n",
    "    def extract_frames(self, video_path):\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            frames = [np.zeros((224, 224, 3), dtype=np.uint8)] * self.frames_per_video\n",
    "            return frames\n",
    "\n",
    "        count_frame = 0\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        if(total_frames >= self.frames_per_video):           \n",
    "            frame_indices = np.linspace(0, total_frames-1, self.frames_per_video, dtype=int)\n",
    "            \n",
    "            while count_frame < self.frames_per_video:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_indices[count_frame])\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                    \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame)\n",
    "                count_frame += 1\n",
    "\n",
    "        else:\n",
    "            while True:        \n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame)\n",
    "        \n",
    "            while len(frames) < (self.frames_per_video):\n",
    "                frames.append(frames[-1])\n",
    "        \n",
    "        cap.release()\n",
    "        return frames\n",
    "                \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        frames = self.extract_frames(video_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "\n",
    "        else:\n",
    "            frames = [torch.tensor(frame).permute(2,0,1).float() / 255.0 for frame in frames]\n",
    "\n",
    "        frames_tensor = torch.stack(frames)\n",
    "\n",
    "        return (frames_tensor, torch.tensor(label, dtype=torch.long))\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "1922e980-6541-4607-afff-076c0f0f7b73",
    "_uuid": "562db88d-3094-414d-8513-cf08c3cc71a6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.378828Z",
     "iopub.status.busy": "2025-09-20T08:43:17.378574Z",
     "iopub.status.idle": "2025-09-20T08:43:17.400667Z",
     "shell.execute_reply": "2025-09-20T08:43:17.400140Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.378806Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/faceforensics/FF++\"\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    \n",
    "    real_path = os.path.join(data_path, \"real\")\n",
    "    fake_path = os.path.join(data_path, \"fake\")\n",
    "\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "\n",
    "    if os.path.exists(real_path):\n",
    "        real_videos = [f for f in os.listdir(real_path)]\n",
    "\n",
    "        for video in real_videos:\n",
    "            video_paths.append(os.path.join(real_path, video))\n",
    "            labels.append(0)\n",
    "\n",
    "    if os.path.exists(fake_path):\n",
    "        fake_videos = [f for f in os.listdir(fake_path)]\n",
    "\n",
    "        for video in fake_videos:\n",
    "            video_paths.append(os.path.join(fake_path, video))\n",
    "            labels.append(1)\n",
    "\n",
    "    return video_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "8b204db5-24cf-4240-897b-8573fc05f061",
    "_uuid": "92e907a8-21f8-4c63-a746-a62b083b2f8e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.402572Z",
     "iopub.status.busy": "2025-09-20T08:43:17.402343Z",
     "iopub.status.idle": "2025-09-20T08:43:17.422890Z",
     "shell.execute_reply": "2025-09-20T08:43:17.422286Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.402557Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/input/faceforensics/FF++\"\n",
    "\n",
    "video_paths, labels = load_dataset(file_path)\n",
    "\n",
    "print(len(video_paths))\n",
    "print(len(labels))\n",
    "print(list(set(labels)))\n",
    "print(video_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "75115891-b85f-42a4-819c-68f16cefd997",
    "_uuid": "e09b7ef3-19b6-456f-af51-83f859755d51",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.423688Z",
     "iopub.status.busy": "2025-09-20T08:43:17.423500Z",
     "iopub.status.idle": "2025-09-20T08:43:17.437248Z",
     "shell.execute_reply": "2025-09-20T08:43:17.436581Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.423674Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "68938e75-828d-47c6-a242-52cb64933bf6",
    "_uuid": "f35c26a8-305e-4169-b70d-b4d29f06a197",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.438092Z",
     "iopub.status.busy": "2025-09-20T08:43:17.437938Z",
     "iopub.status.idle": "2025-09-20T08:43:17.463157Z",
     "shell.execute_reply": "2025-09-20T08:43:17.462435Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.438080Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=None and train_size=0.7, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_paths, temp_paths, train_labels, temp_labels \u001b[38;5;241m=\u001b[39m train_test_split(video_paths, labels, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, \n\u001b[0;32m      2\u001b[0m                                                               random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mlabels, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m val_paths, test_paths, val_labels, test_labels \u001b[38;5;241m=\u001b[39m train_test_split(temp_paths, temp_labels, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, \n\u001b[0;32m      5\u001b[0m                                                                   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtemp_labels, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\91741\\anaconda3\\envs\\pytorch_vision\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\91741\\anaconda3\\envs\\pytorch_vision\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2786\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2787\u001b[0m )\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\91741\\anaconda3\\envs\\pytorch_vision\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2419\u001b[0m     )\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=None and train_size=0.7, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(video_paths, labels, train_size=0.7, \n",
    "                                                              random_state=42, stratify=labels, shuffle=True)\n",
    "\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(temp_paths, temp_labels, train_size=0.7, \n",
    "                                                                  random_state=42, stratify=temp_labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a267dfdb-3e9b-4e8d-b986-f050e0de9559",
    "_uuid": "226a7192-7959-4e0c-93a2-5884401ac4f7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.464037Z",
     "iopub.status.busy": "2025-09-20T08:43:17.463878Z",
     "iopub.status.idle": "2025-09-20T08:43:17.479579Z",
     "shell.execute_reply": "2025-09-20T08:43:17.478936Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.464024Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 140, 0: 140})\n",
      "Counter({0: 42, 1: 42})\n",
      "Counter({0: 18, 1: 18})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(train_labels))\n",
    "print(Counter(val_labels))\n",
    "print(Counter(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "668e7c1b-3235-4bc5-9b6e-8965efae2b47",
    "_uuid": "f6e6855d-f1f7-4c49-b84c-9cdcfb0d9615",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.481995Z",
     "iopub.status.busy": "2025-09-20T08:43:17.481791Z",
     "iopub.status.idle": "2025-09-20T08:43:17.495099Z",
     "shell.execute_reply": "2025-09-20T08:43:17.494537Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.481981Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(video_paths=train_paths, labels=train_labels, transform=train_transform, frames_per_video=frames_per_video)\n",
    "val_dataset = VideoDataset(video_paths=val_paths, labels=val_labels, transform=val_transform, frames_per_video=frames_per_video)\n",
    "test_dataset = VideoDataset(video_paths=test_paths, labels=test_labels, transform=val_transform, frames_per_video=frames_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f7fdf3a-c226-4538-8e9d-9b9315bb87d4",
    "_uuid": "150fd4a5-ef81-48b3-b648-89542d7093f4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.496397Z",
     "iopub.status.busy": "2025-09-20T08:43:17.496159Z",
     "iopub.status.idle": "2025-09-20T08:43:17.514318Z",
     "shell.execute_reply": "2025-09-20T08:43:17.513753Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.496380Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) \n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c36deb64-2593-462a-a270-3897c970ec12",
    "_uuid": "f42dcfa1-b62b-4d19-acdd-add5a1db249f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1cbb04ff-62a5-4aeb-b266-4010507c2c40",
    "_uuid": "eb9a2fc6-1b28-41f9-9e89-bc1d379ea7e9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.515702Z",
     "iopub.status.busy": "2025-09-20T08:43:17.515070Z",
     "iopub.status.idle": "2025-09-20T08:43:17.531989Z",
     "shell.execute_reply": "2025-09-20T08:43:17.531249Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.515678Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model_one_epoch(model, train_loader, optimizer, loss_fn, scheduler=None):\n",
    "\n",
    "    total_train_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "        \n",
    "    model.train()\n",
    "    train_tqdm = tqdm(train_loader, desc=\"Training: \")\n",
    "\n",
    "    for batch_idx, (frames, labels) in enumerate(train_tqdm):\n",
    "        \n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        frames = frames.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(frames)             \n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        probs = torch.softmax(output, dim=1)[:,1]\n",
    "\n",
    "        all_preds.extend(predicted.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "        \n",
    "        train_tqdm.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    \n",
    "    train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    train_precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_labels, all_preds, average=\"binary\")    \n",
    "    \n",
    "\n",
    "    return (\n",
    "        train_loss,\n",
    "        train_accuracy,\n",
    "        train_precision,\n",
    "        train_recall,\n",
    "        train_f1,\n",
    "        all_probs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "18afd431-f7b7-4b97-8a18-b531225e5fa3",
    "_uuid": "adb35dac-05b8-4b43-9dca-568953d0b125",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.533559Z",
     "iopub.status.busy": "2025-09-20T08:43:17.533397Z",
     "iopub.status.idle": "2025-09-20T08:43:17.554507Z",
     "shell.execute_reply": "2025-09-20T08:43:17.553985Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.533546Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def val_model_one_epoch(model, val_loader, loss_fn):\n",
    "    \n",
    "    total_val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    best_model_state = None\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "            \n",
    "        val_tqdm = tqdm(val_loader, desc=\"Validation: \")\n",
    "        \n",
    "        for frames, labels in val_tqdm:\n",
    "            frames, labels = frames.to(device), labels.to(device)\n",
    "            frames = frames.permute(0, 2, 1, 3, 4)\n",
    "                    \n",
    "            output = model(frames)\n",
    "            loss = loss_fn(output, labels)\n",
    "    \n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            probs = torch.softmax(output, dim=1)[:,1]\n",
    "                    \n",
    "            all_preds.extend(predicted.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "            val_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    \n",
    "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    val_precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "    val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    return (\n",
    "        val_loss,\n",
    "        val_accuracy,\n",
    "        val_precision,\n",
    "        val_recall,\n",
    "        val_f1,\n",
    "        all_probs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4970bf04-b004-4a72-b065-ad1f4a99949b",
    "_uuid": "32b5b079-9a32-4578-80c8-98d17c95523f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d40b270c-e035-4f90-ae5e-ba700939ffe4",
    "_uuid": "607b44c3-e391-4a3e-a55b-f5865f152e0d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 1. EfficientNet v2 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13611f7e-6bbb-4148-a67b-21ba5a45aac1",
    "_uuid": "90ba18d0-b7b2-4ed5-9a8a-7e11edf13609",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:17.555295Z",
     "iopub.status.busy": "2025-09-20T08:43:17.555103Z",
     "iopub.status.idle": "2025-09-20T08:43:18.102362Z",
     "shell.execute_reply": "2025-09-20T08:43:18.101568Z",
     "shell.execute_reply.started": "2025-09-20T08:43:17.555280Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "model = r3d_18(pretrained=True).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "13b192b0-8308-4cf2-b24b-89dc2decfdff",
    "_uuid": "dbb6c7ac-6bf4-442b-92e4-9c448db8ba09",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "163d4ca1-9744-479e-a7af-4fce63aa847c",
    "_uuid": "9c0e2aef-6a52-493e-a75d-3af331f19309",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:18.103594Z",
     "iopub.status.busy": "2025-09-20T08:43:18.103372Z",
     "iopub.status.idle": "2025-09-20T08:43:18.110272Z",
     "shell.execute_reply": "2025-09-20T08:43:18.109682Z",
     "shell.execute_reply.started": "2025-09-20T08:43:18.103576Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "#model = XceptionNet(num_classes=2, num_frames=frames_per_video).to(device)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.0001,\n",
    "    weight_decay = 0.01\n",
    ")\n",
    "\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0 = 8,\n",
    "    T_mult = 2,\n",
    "    eta_min = 1e-6\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b387487e-bbc6-40f6-9aa2-e2e11dae427b",
    "_uuid": "526cc707-3a3e-4001-8eb0-3152d2029d0d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:18.111288Z",
     "iopub.status.busy": "2025-09-20T08:43:18.111009Z",
     "iopub.status.idle": "2025-09-20T08:43:18.126963Z",
     "shell.execute_reply": "2025-09-20T08:43:18.126311Z",
     "shell.execute_reply.started": "2025-09-20T08:43:18.111264Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_val_f1 = 0\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 4\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6938e057-a69b-4328-b19e-4b8fc4cf28fa",
    "_uuid": "a795871f-9b63-4db9-a1e7-50e99e6ec8f1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:18.128228Z",
     "iopub.status.busy": "2025-09-20T08:43:18.127983Z",
     "iopub.status.idle": "2025-09-20T08:43:18.150410Z",
     "shell.execute_reply": "2025-09-20T08:43:18.149769Z",
     "shell.execute_reply.started": "2025-09-20T08:43:18.128205Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "92e7ab03-86f6-46c7-b294-d0c74956add5",
    "_uuid": "d5ab4917-805a-4553-ab1c-59d3c1649525",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T08:43:18.151594Z",
     "iopub.status.busy": "2025-09-20T08:43:18.151302Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 1/35 [01:42<58:00, 102.38s/it, Loss=0.7272]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(f\"\\nEpoch: {epoch+1}/{epochs}\")\n",
    "\n",
    "    train_loss, train_accuracy, train_precision, train_recall, train_f1, train_probs = train_model_one_epoch(model = model, \n",
    "                        train_loader = train_loader, optimizer = optimizer, loss_fn = loss_fn)\n",
    "\n",
    "    val_loss, val_accuracy, val_precision,val_recall, val_f1, val_probs = val_model_one_epoch(model = model, \n",
    "                        val_loader = val_loader, loss_fn = loss_fn)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"\\nTRAINING METRICS: \")\n",
    "    print(f\"Loss: {train_loss}  Accuracy: {train_accuracy}  Precision: {train_precision}  Recall: {train_recall}  F1 Score: {train_f1}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"\\nValiation METRICS: \")\n",
    "    print(f\"Loss: {val_loss}  Accuracy: {val_accuracy}  Precision: {val_precision}  Recall: {val_recall}  F1 Score: {val_f1}\")\n",
    "\n",
    "    \n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        print(\"Best Model Updated\")\n",
    "\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early Stopping Triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ba92b55e-1db6-47e5-863e-e1fa96ef9e06",
    "_uuid": "7ce2c153-d603-426e-8e2c-bc151f839c62",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a155141d-db31-4c8e-9983-c6ffab0c2fed",
    "_uuid": "7d2ed6ea-8f61-4ef2-80eb-da67978599c2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/working/deepfake_trial.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c81012ab-5c2a-4106-be5b-941ba34abe02",
    "_uuid": "b6f7667b-b0c4-422d-80a2-49a16184ed9e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy, test_precision,test_recall, test_f1, test_probs = val_model_one_epoch(model = model, \n",
    "                        val_loader = test_loader, loss_fn = loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1bb8cb3f-7b75-42d0-9252-ab5c1755219f",
    "_uuid": "eddc075f-9917-4c2b-99d1-7937c1b16432",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(train_labels, train_probs))\n",
    "print(roc_auc_score(val_labels, val_probs))\n",
    "print(roc_auc_score(test_labels, test_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "53f628d7-ef8e-4dc4-9208-03beb34330f1",
    "_uuid": "c82169e9-9ef4-4637-8d55-a8a9f7a78e07",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "379b9424-9341-46cc-b70e-14ca21024a47",
    "_uuid": "1b80df7e-0411-4015-8b8b-aa0a0b7f3e4c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4434986,
     "sourceId": 7615428,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (pytorch_vision)",
   "language": "python",
   "name": "pytorch_vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
